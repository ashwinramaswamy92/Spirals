---
title: "Report for Ashley"
author: "Franti≈°ek Kalvas"
date: '2022-03-07'
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
## Encoding: UTF-8

rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
```

## Packages etc.

```{r}
library(stargazer)
library(dplyr)
library(tidyr)
library(ggplot2)


# My own functon for renaming in Tidyverse
prejmenuj = function(data, positions, new.names) {
  names(data)[positions] = new.names
  data
}
```



## Loading data

Data are at <http://github.com/frantisek901/Spirals/Experiment>. Experiment is still running and I, Francesco, from time to time actualize the `*.csv` files at GitHub, then I run script `experiment.R` which loads the data. Later version probably finds better names for variables, but now, I use default names from NetLogo experiment.

Who is not interested in working with megabytes of `*.csv files`, might use compiled `*.RData`, there are two files: `shortData.RData`, which is main data file from experiments running only 365 steps, these data are extended by extra simulations with low size of small-world network neighborhood; and `longData.RData`, which is additional data file from experiments running 3650 steps -- thanks to it we might test the effect of simulation length.

Now we load these data:
```{r loading}
load("shortData.RData")
load("longData.RData")

```



## Regressions

On the two following pages, there are 4 regressions in 2 tables (I'm starting with `stargazer`, later I will produce better output, but for now...). The first table uses ESBG polarization measure, after 365 and 3650 steps, the second uses my normalized polarization measure after same number of steps.

\pagebreak

```{r regression1, echo=FALSE}
# 365 ticks
nn = lm(normalized_365~id_threshold+`use_identity?`+boundary+mode+`tolerance-level`+`p-speaking-level`+`conformity-level`+`p-random`+`n-neis`,res) 
ne = (lm(ESBG_365~id_threshold+`use_identity?`+boundary+mode+`tolerance-level`+`p-speaking-level`+`conformity-level`+`p-random`+`n-neis`,res))

# 3650 ticks
ln = (lm(normalized_3650~id_threshold+`use_identity?`+boundary+mode+`tolerance-level`+`p-speaking-level`+`conformity-level`+`p-random`+`n-neis`, long))
le = (lm(ESBG_3650~id_threshold+`use_identity?`+boundary+mode+`tolerance-level`+`p-speaking-level`+`conformity-level`+`p-random`+`n-neis`, long))

stargazer(ne, le, type = "text")

```

\pagebreak

```{r regression2, echo=FALSE}
stargazer(nn, ln, type = "text")

```

### Note:

1. Variables `mode:vaguely-speak` and `use_identity?` are binary, `n-neis` is measured on scale 1--64, and all other variables (`id_threshold`, `boundary` etc.) are measured on scale 0--1.

2. I check the problem of `use_identity?` -- I estimated same regression model on sub-sample of simulation with `use_identity?==TRUE`, naturally, effect of mere `use_identity?` is not estimable, but good news is that effect of `id_threshold` is completely same (OK, up to 5th decimal place).

3. Just for curiosity I estimated the model for subsample `use_identity?==FALSE`, I was surprised that all effects were roughly by one order lower ($10^{-1}$).


## Graphs  

### Sampling  

I produced graphs after some random sampling. Both files standard (365 steps) and long (3650 steps) are huge with many thousands of observations. So I created two samples, each of 10,000 observations -- 5,000 simulations using identity, 5,000 not using identity.

```{r sampling}

res_sample = sample_n(res[res$`use_identity?`,], 5000) %>%
  add_row(sample_n(res[!res$`use_identity?`,], 5000)) %>%
  sample_n(10000)

long_sample = sample_n(long[long$`use_identity?`,], 5000) %>%
  add_row(sample_n(long[!long$`use_identity?`,], 5000)) %>%
  sample_n(10000)

```



### Inter-quartile range

Here we look at depiction of distribution of interquartile range of both opinions. The first graph is made from standard (365 steps) data, the second from long (3,650 steps) data.   

```{r graph1, fig.width=5.8}

res_sample %>% 
  ggplot(aes(x = iqr_op1_final, y = iqr_op2_final, col = `use_identity?`)) +
  geom_point(alpha = 0.35) +
  labs(title = "IQR of both opinions: after 365 steps", 
       caption = "Sample of 5,000 simulations using udentity and 5,000 simulations not using identity.") +
  theme_minimal()



```



```{r graph2, fig.width=5.8}

long_sample %>% 
  ggplot(aes(x = iqr_op1_final, y = iqr_op2_final, col = `use_identity?`)) +
  geom_point(alpha = 0.35) +
  labs(title = "IQR of both opinions: after 3,650 steps", 
       caption = "Sample of 5,000 simulations using udentity and 5,000 simulations not using identity.") +
  theme_minimal()

```

For me the basic logic is same in both graphs: some part of simulations ends up with consensus, mainly its simulations not using identity (red dots). Simulation using identity (turquoise dots) sometimes ends up with consensus as well, but also frequently ends up polarized, which is reflected by turquoise 'perimeter'. It seems to me that this basic logic -- identity use = perimeter of discord -- is same regardless the length of simulation.   
  
But different is cleanness of this pattern. In long data (3,650 steps) it is very clear and there are almost no observations between 'red consensus dot' in left down corner and 'turquoise discord perimeter'.  In standard data (365 steps) there are some observations and the perimeter seems fatter. The result is obvious: some standard simulations (365 steps) ended too early, because their 'longer twins' moved from 'discord perimeter' or space in between to 'concensus dot'. So, let's check the differences in polarization between standard and long data:

```{r graph3, fig.width=5.8}
df = res %>% mutate(file = "standard") %>% 
  rename(ESBG = ESBG_365, normalized = normalized_365, identity = `use_identity?`) %>% 
  add_row(long %>% mutate(file = "long") %>% 
            rename(ESBG = ESBG_3650, normalized = normalized_3650, identity = `use_identity?`)) %>% 
  group_by(file, identity) %>% 
  summarise(ESBG = mean(ESBG), normalized = mean(normalized)) %>% 
  pivot_longer(cols = c(ESBG, normalized), names_to = "polarization_measure", values_to = "polarization")

ggplot(df, aes(x = file, y = polarization, fill = identity)) +
  facet_wrap(vars(polarization_measure)) +
  geom_col(position = position_dodge()) +
  labs(title = "Comparison of average polarization in \nlong (3,650 steps) and standard (365 steps) simulations\nby polarization measure and identity use (TRUE/FALSE)", caption = "Full aggregated sample.") +
  theme_minimal()

```


We see that long (3,650 steps) simulation are tiny slightly less polarized than short (365 steps) ones, i.e. on the average, the polarization in further more than 3,000 steps slightly decreases from initial value. We also see that `normalized` measure shows slightly higher polarization than `ESBG`. So, we might be quite confident that the length of simulation doesn't spoil the results that much -- since there is some tiny differences in aggregate results, it makes sense to do further analyses on individual level, i.e. level of individual simulation, and compute and plot how many times polarization increases from 365th to 3,650th step and how much, but for now we see that after 365 steps we received almost same picture as after 3,650 steps.  

But the main difference is obviously whether we use identity process or not -- regardless the level of identity threshold (but note that we simulate it only for values 0.39, 0.49, 0.59, since it is so important parameter, we now could look at it in more detail). So, let's look now graphically in same way on data, as we did in regression tables:

```{r graph4, fig.width=5.8, fig.height=5.8}
df = res %>% mutate(file = "standard") %>% 
  rename(ESBG = ESBG_365, normalized = normalized_365, identity = `use_identity?`) %>% 
  add_row(long %>% mutate(file = "long") %>% 
            rename(ESBG = ESBG_3650, normalized = normalized_3650, identity = `use_identity?`)) %>% 
  group_by(file, id_threshold, identity, boundary, mode) %>% 
  summarise(ESBG = mean(ESBG), normalized = mean(normalized)) %>% 
  pivot_longer(cols = c(ESBG, normalized), names_to = "polarization_measure", values_to = "polarization")

# `tolerance-level`             -0.024***                      -0.025***          
#                                (0.001)                        (0.001)           
#                                                                                 
# `p-speaking-level`            -0.018***                      -0.011***          
#                                (0.002)                        (0.003)           
#                                                                                 
# `conformity-level`            -0.056***                      0.011***           
                               # (0.003)                        (0.003)        

df %>% filter(file == "standard") %>% 
  ggplot(aes(fill = as.factor(id_threshold), y = polarization, x = as.factor(boundary))) +
  facet_grid(cols = vars(identity, polarization_measure), rows = vars(mode)) +
  geom_col(position = position_dodge()) +
  labs(title = "Comparison of average polarization in standard (365 steps) simulations\nby polarization measure, identity use (TRUE/FALSE)\nidentity threshold (0.39, 0.49, 0.59) and mode (listen/speak)", caption = "Full aggregated sample.") +
  theme_minimal()  +
  theme(legend.position = "bottom")


```


Again same graph, just for better view only simulations using identity.


```{r graph5, fig.width=5.8, fig.height=5.8}
df %>% filter(file == "standard", identity) %>% 
  ggplot(aes(fill = as.factor(id_threshold), y = polarization, x = as.factor(boundary))) +
  facet_grid(cols = vars(identity, polarization_measure), rows = vars(mode)) +
  geom_col(position = position_dodge()) +
  labs(title = "Comparison of average polarization in standard (365 steps) simulations\nby polarization measure, identity threshold (0.39, 0.49, 0.59) and mode (listen/speak)", caption = "Full aggregated sample.") +
  theme_minimal() +
  theme(legend.position = "bottom")

```

In previous graph we saw that while some polarisation might happen even without using identity (especially with narrower boundaries), more polarized simulations on average are that using identity. Effect of identity threshold is non-linear: in simulations with 'openly listen' mode the main polarization increase is between 0.39 and 0.49 values, in mode 'vaguely speak' between values 0.49 and 0.59 (but generally, the later mode is less polarized). It is also interesting, that in mode 'vaguely speak' with boundary widening the polarization always decreases, but in mode 'openly listen' this happens only for the lowest identity threshold value (0.39), for other threshold values (0.49, 0.59) the polarization stays same with widening of boundary or even very slightly increases! 

The last result is very surprising -- Hegselmann-Krause model usually finds overall concensus and avoids polarization with wider boundary, it's one of basic results. But when we introduce identity, then this old true changes or is contingent on simulation mode (speaking/listening) and identity threshold. The classical HK findings still hold true, but only for 'vaguely speak' mode and low identity threshold values.

