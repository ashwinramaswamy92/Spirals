---
title: "Seeking for the two-way phase-transition"
author: 
  - name: "František Kalvas"
    url: https://github.com/frantisek901/Spirals/Experiment
    affiliation: Department of Sociology, University of West Bohemia in Pilsen
    affiliation_url: https://les.zcu.cz
date: '2022-03-28'
output: 
  html_document: 
    toc: true
    toc_float: true
    code_folding: hide
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
## Encoding: UTF-8

rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Main focus of this side project is to find phase-transition which happen when we are changing boundary/`Acceptability of different opinion` and `Narrowness of identity group`. Result should be a simple graph showing how ESBG polarization changes with change of `Acceptability of different opinion` and `Narrowness of identity group`.  

Note: Experiment is still running, we are at 26 complete sets of all values combinations out of 120. Also note, that it seems that we are not done yet, we probably will need more sets than 120 and more values of `Narrowness of identity group`.
  

```{r echo=FALSE, include=FALSE, message=FALSE}
library(stargazer)
library(dplyr)
library(tidyr)
library(readr)
library(ggplot2)
library(lmtest)
library(forcats)
library(sjmisc)
library(jtools)
library(huxtable)
library(knitr)


# My own functon for renaming in Tidyverse
prejmenuj = function(data, positions, new.names) {
  names(data)[positions] = new.names
  data
}
```

## Processing raw data files

```{r data processing, echo=FALSE, message=FALSE}
## Now we need to run it, since experiment is still running, but later, after data finalization, we might comment this out:
phase2w = read_csv("experiment01part41.csv", skip = 6) %>% 
            select(2, 3, identity = 4, 5, 6, step = 48, ESBG = ESBSG_polarization_final) %>%
  add_row(read_csv("experiment01part42.csv", skip = 6) %>% 
            select(2, 3, identity = 4, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part42b.csv", skip = 6) %>% 
            select(2, 3, identity = 4, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part43.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part44.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part44b.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part44c.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part45.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part46.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part46b.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part46c.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part51.csv", skip = 6) %>% 
            select(2, 3, identity = 4, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part51b.csv", skip = 6) %>% 
            select(2, 3, identity = 4, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part51c.csv", skip = 6) %>% 
            select(2, 3, identity = 4, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part51d.csv", skip = 6) %>% 
            select(2, 3, identity = 4, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part52.csv", skip = 6) %>% 
            select(2, 3, identity = 4, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part52b.csv", skip = 6) %>% 
            select(2, 3, identity = 4, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part53.csv", skip = 6) %>% 
            select(2, 3, identity = 4, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part53b.csv", skip = 6) %>% 
            select(2, 3, identity = 4, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part54.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part54b.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part54c.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part55.csv", skip = 6) %>%
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part55b.csv", skip = 6) %>%
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part56.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part56b.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part57.csv", skip = 6) %>%
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part57b.csv", skip = 6) %>%
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part57c.csv", skip = 6) %>%
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part58.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part58b.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  add_row(read_csv("experiment01part59.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>% 
  add_row(read_csv("experiment01part59b.csv", skip = 6) %>% 
            select(2, 4, identity = 3, 5, 6, step = 48, ESBG = ESBSG_polarization_final)) %>%
  unique()

save(phase2w, file = "phase2w.RData")

```


## Loading data

Data are at <https://github.com/frantisek901/Spirals/tree/master/Experiment>. Experiment is still running and I, FranČesko, from time to time actualize the `*.csv` files at GitHub, then I run script `experiment.R` which loads the data. Now, 2022-03-25, we are at 20 %, roughly. Who is not interested in working with megabytes of `*.csv files`, might use compiled `phase2w.RData`.  

<!-- For avoiding statistical artifact we sampling data -- for each combination of important variables same number of observations/simulations. Here we must note, that per 1 simulation not using identity we have 3 simulations using identity, since it makes no sense to vary `Narrownes of identity group` in case we are not using identity in the model.   -->

Now we load and aggregate these data and factorize and rename selected variables:  

```{r loading, message=FALSE}
## Loading stored data
load("phase2w.RData")


## Firstly, we have to find, what is the highest complete RS, i.e. set of all parameters' combinations simulated:
RS_complete = (phase2w %>% group_by(RS) %>% summarise(n = n()) %>% filter(n == max(n)))$RS 


## Preparing individual data 'dfi'
dfi = phase2w %>% 
  ## Filtering variables:
  filter(RS %in% RS_complete, identity) %>%  #  | (RS >= 61 & RS <= 96),  
  ## Denormalizing ESBG:
  mutate(ESBG = ESBG * sqrt(opinions))


## Summarising 'dfi' into 'dfs':
dfs = dfi %>% 
  group_by(opinions, boundary, identity, id_threshold) %>% 
  summarise(ESBG = mean(ESBG)) %>% ungroup() %>% 

  ## Renaming variables according 2022-03-18 meeting:
  prejmenuj(1:4, c("Opinion dimensions:", "Acceptability of different opinion:", "Identity:", 
                    "Narrowness of identity group:"))

```

#### NOTE:  

I de-normalized ESBG, i.e. I multiply. I just noticed that systematically ESBG is lower and also much denser in higher dimensions. I have also substantive/philosophical reasons for this de-normalization, now I will try it and describe the reasons for de-normalization later in detail. But just briefly: 

I think that agents do not know in how many dimensions they are and what is the maximum posible distance, they feel polarisation reegarding the other group not regarding the group and the possible maxima of distance, let's do following thought experiment:

Our agents living in 1D, they discuss just one topic, they are divided in two camps of equal size and these two camps are at the poles -1 and +1 of their opinion space, the polarization is maximal, ESBG is 1. Then we take this strange world on a string and put it on the table, now they are in 2D world, their distance is same since the don't change it, they should stil feel polarization of margin ESBG=1 since nothing changed. Then we recognize that table is in the roomm -- 3D, then we rocignize time -- 4D... But polarization should be still same, since these agent don't change their positions.

So, this was the argument :-) and now let's look, how results change after de-normalization of ESBG...

GREAT! Results look GREAT! Now the polarization is more ballanced over dimensions, but still, even after de-normalization, holds true that the more dimensions the less polarization.  



# Graphs  

Now, let's show our results graphically!  

## Color maps  

### Smaller maps, one by one  

```{r color map1, fig.width=8, fig.height=6, warning=FALSE}
dfs %>% 
  ggplot() +
  aes(x = `Acceptability of different opinion:`, col = ESBG, fill = ESBG,
      y = `Narrowness of identity group:`) +
  facet_wrap(vars(`Opinion dimensions:`), ncol=3) +
  geom_point(alpha = 1, size = 1.75, shape = 22) +
  scale_fill_gradient2(low = "green", mid = "red", high = "black", midpoint = 0.3) +
  scale_color_gradient2(low = "green", mid = "red", high = "black", midpoint = 0.3) +
  scale_y_continuous(breaks = seq(0.05, 0.85, 0.05)) +
  scale_x_continuous(breaks = seq(0.05, 0.50, 0.05)) +
  labs(title = "Change of polarization in simulations by 'Opinion dimensions' (1, 2, 4), 'Narrowness of identity group' (0.05--0.85) and\n'Average acceptability of different opinions' (0.05--0.5)",
       x = "Average acceptability of different opinions") +
  guides(alpha = "none") +
  theme_minimal() +
  theme(legend.position = "top")  

```

1) I love these pictures! Whole my life I'd like to produce something meaningful looking like this -- and here I am!
2) the more dimensions the less polarization,
3) the least polarized region is quarter of circle in the right bottom corner, then the left-hand side stripe, and the most polarized is the resting region (the most polarized part of this region seems to move with change of dimensions, but may be it is the artifact of low number of simulations -- sometimes it is upper-right corner, sometimes upper border, sometimes right border)


### Detailed maps: one after one  

Just for a try, same map, but more detailed and with panels organized in column insted of in a row:

```{r color map2, fig.width=8, fig.height=40, warning=FALSE}
dfs %>% 
  ggplot() +
  aes(x = `Acceptability of different opinion:`, fill = ESBG, col = ESBG, label = round(100*ESBG, 0),
      y = `Narrowness of identity group:`) +
  facet_wrap(vars(`Opinion dimensions:`), ncol=1) +
  geom_point(alpha = 1, size = 6.6, shape = 22) +
  geom_text(color = "white", size = 2) +
  scale_fill_gradient2(low = "green", mid = "red", high = "black", midpoint = 0.3) +
  scale_color_gradient2(low = "green", mid = "red", high = "black", midpoint = 0.3) +
  scale_y_continuous(breaks = seq(0.05, 0.85, 0.05), labels = seq(0.05, 0.85, 0.05)) +
  scale_x_continuous(breaks = seq(0.05, 0.50, 0.05), labels = seq(0.05, 0.50, 0.05)) +
  labs(title = "Change of polarization in simulations by 'Opinion dimensions' (1, 2, 4), 'Narrowness of identity group' (0.05--0.85) and\n'Average acceptability of different opinions' (0.05--0.5)",
       x = "Average acceptability of different opinions", 
       caption = "Note: Numbers indicate polarization, they are equal to `round(100 * ESBG, 0)`.") +
  guides(alpha = "none") +
  theme_minimal() +
  theme(legend.position = "top")  

```



## Pulped clouds  

For the first graph on pulped clouds we aggregate `Acceptability of different opinion` into 13 categories (we just round 121 original values to 2 digits). Two different levels of polarization are seeable here, but it doesn't look like clouds...   

### Acceptability: reduced boxplot

```{r graph1, fig.width=8, fig.height=12, warning=FALSE}
## For presenting variability we try now boxplots on individual data (non-aggregated):
dfi %>%
  filter(round(100 * id_threshold, 0) %in% seq(5, 85, 10)) %>% 
  # sample_n(2000) %>%
  ## Selecting variables:
  select(opinions, boundary, id_threshold, ESBG) %>% 
  mutate(id_threshold = factor(id_threshold),
         opinions = factor(opinions)) %>% 
  
  ## Renaming variables according 2022-03-18 meeting:
  prejmenuj(1:3, c("Opinion dimensions:", "Acceptability of different opinion:",  
                    "Narrowness of identity group:")) %>% 

  ## Graph itself:
  ggplot() +
  aes(x = `Acceptability of different opinion:`, y = ESBG, 
      fill = `Narrowness of identity group:`,
      col = `Narrowness of identity group:`, 
      group = `Acceptability of different opinion:`) +
  facet_wrap(vars(`Narrowness of identity group:`, `Opinion dimensions:`), ncol=3) +
  geom_boxplot(alpha = 0.2) +
  geom_jitter(alpha = 0.2) +
  scale_x_continuous(breaks = seq(0.05, 0.50, 0.05)) +
  labs(title = "Change of polarization in simulations by 'Opinion dimensions' (1, 2, 4),\n'Narrowness of identity group' (0.05--0.85) and 'Average acceptability of different opinions' (0.05--0.5)",
       x = "Average acceptability of different opinions", y = "Polarization") +
  guides(fill = "none", color = "none") +
  theme_minimal() +
  theme(legend.position = "top")  

```



### Acceptability: full boxplot

Now same graph, but with every value:

```{r graph2, fig.width=8, fig.height=90, warning=FALSE}
## For presenting variability we try now boxplots on individual data (non-aggregated):
dfi %>%
  # sample_n(20000) %>%
  ## Selecting variables:
  select(opinions, boundary, id_threshold, ESBG) %>% 
  
  ## Changing some variables to factors:
  mutate(id_threshold = factor(id_threshold),
         opinions = factor(opinions)) %>% 
 
  ## Renaming variables according 2022-03-18 meeting:
  prejmenuj(1:3, c("Opinion dimensions:", "Acceptability of different opinion:",  
                    "Narrowness of identity group:")) %>% 

  ## Graph itself:
  ggplot() +
  aes(x = `Acceptability of different opinion:`, y = ESBG, 
      fill = `Narrowness of identity group:`,
      col = `Narrowness of identity group:`, 
      group = `Acceptability of different opinion:`) +
  facet_wrap(vars(`Narrowness of identity group:`, `Opinion dimensions:`), ncol=3) +
  geom_boxplot(alpha = 0.2) +
  geom_jitter(alpha = 0.2) +
  scale_x_continuous(breaks = seq(0.05, 0.50, 0.05)) +
  labs(title = "Change of polarization in simulations by 'Opinion dimensions' (1, 2, 4),\n'Narrowness of identity group' (0.05--0.85) and 'Average acceptability of different opinions' (0.05--0.5)",
       x = "Average acceptability of different opinions", y = "Polarization") +
  guides(fill = "none", color = "none") +
  theme_minimal() +
  theme(legend.position = "top")  

```


### Acceptability: reduced scatter plot  

Now, same data but slightly different graph

```{r graph3, fig.width=8, fig.height=12, warning=FALSE}
## For presenting variability we try now scatter plot only on individual data (non-aggregated):
dfi %>%
  filter(round(100 * id_threshold, 0) %in% seq(5, 85, 10)) %>% 
  # sample_n(2000) %>%
  ## Selecting variables:
  select(opinions, boundary, id_threshold, ESBG) %>% 

  ## Changing some variables to factors:
  mutate(id_threshold = factor(id_threshold),
         opinions = factor(opinions)) %>% 

  ## Renaming variables according 2022-03-18 meeting:
  prejmenuj(1:3, c("Opinion dimensions:", "Acceptability of different opinion:",  
                    "Narrowness of identity group:")) %>% 

  ## Graph itself:
  ggplot(aes(x = `Acceptability of different opinion:`, y = ESBG, 
             fill = `Narrowness of identity group:`,
             col = `Narrowness of identity group:`, 
             group = `Acceptability of different opinion:`)) +
  facet_wrap(vars(`Narrowness of identity group:`, `Opinion dimensions:`), ncol=3) +
  geom_point(alpha = 0.15) +
  scale_x_continuous(breaks = seq(0.05, 0.50, 0.05)) +
  labs(title = "Change of polarization in simulations by 'Opinion dimensions' (1, 2, 4),\n'Narrowness of identity group' (0.05--0.85) and 'Average acceptability of different opinions' (0.05--0.5)",
       x = "Average acceptability of different opinions", y = "Polarization") +
  guides(fill = "none", color = "none") +
  theme_minimal() +
  theme(legend.position = "top")
```



### Acceptability: full scatter plot  

```{r graph4, fig.width=8, fig.height=90, warning=FALSE}
## For presenting variability we try now scatter plot on individual data (non-aggregated):
dfi %>%
  # sample_n(2000) %>%
  ## Selecting variables:
  select(opinions, boundary, id_threshold, ESBG) %>%  
  
  ## Changing some variables to factors:
  mutate(id_threshold = factor(id_threshold),
         opinions = factor(opinions)) %>% 
  
  ## Renaming variables according 2022-03-18 meeting:
  prejmenuj(1:3, c("Opinion dimensions:", "Acceptability of different opinion:",  
                    "Narrowness of identity group:")) %>% 

  ## Graph itself:
  ggplot(aes(x = `Acceptability of different opinion:`, y = ESBG, 
             fill = `Narrowness of identity group:`,
             col = `Narrowness of identity group:`, 
             group = `Acceptability of different opinion:`)) +
  facet_wrap(vars(`Narrowness of identity group:`, `Opinion dimensions:`), ncol=3) +
  geom_point(alpha = 0.15) +
  scale_x_continuous(breaks = seq(0.05, 0.50, 0.05)) +
  labs(title = "Change of polarization in simulations by 'Opinion dimensions' (1, 2, 4),\n'Narrowness of identity group' (0.35--0.6) and 'Average acceptability of different opinions' (0.05--0.3)",
       x = "Average acceptability of different opinions", y = "Polarization") +
  guides(fill = "none", color = "none") +
  theme_minimal() +
  theme(legend.position = "top")
```


## Pulped clouds: Exchanging `Acceptability` and `Narrowness`    


For this set of graph we flip the perspective -- we set `Acceptability of different opinion` as slicing variable, associated with color/fill, on the X axis we assign `Narrowness of identity group`. Let's hope, it helps understand the 2-way phase transition better.  

### Narrownes: reduced boxplot

```{r graph5, fig.width=8, fig.height=12, warning=FALSE}
## For presenting variability we try now boxplots on individual data (non-aggregated):
dfi %>%
  filter(round(100 * boundary, 1) %in% seq(5, 50, 5)) %>% 
  # sample_n(2000) %>%
  ## Selecting variables:
  select(opinions, boundary, id_threshold, ESBG) %>% 
  mutate(boundary = factor(boundary),
         opinions = factor(opinions)) %>% 
  
  ## Renaming variables according 2022-03-18 meeting:
  prejmenuj(1:3, c("Opinion dimensions:", "Acceptability of different opinion:",  
                    "Narrowness of identity group:")) %>% 

  ## Graph itself:
  ggplot() +
  aes(fill = `Acceptability of different opinion:`, y = ESBG, 
      x = `Narrowness of identity group:`,
      group = `Narrowness of identity group:`,
      col = `Acceptability of different opinion:`) +
  facet_wrap(vars(`Acceptability of different opinion:`, `Opinion dimensions:`), ncol=3) +
  geom_boxplot(alpha = 0.2) +
  geom_jitter(alpha = 0.2) +
  scale_x_continuous(breaks = seq(0.05, 0.850, 0.1)) +
  labs(title = "Change of polarization in simulations by 'Opinion dimensions' (1, 2, 4),\n'Narrowness of identity group' (0.05--0.85) and 'Average acceptability of different opinions' (0.05--0.5)",
      y = "Polarization") +
  guides(fill = "none", color = "none") +
  theme_minimal() +
  theme(legend.position = "top")  

```


### Narrownes: full boxplot

Now same graph, but with every value:

```{r graph6, fig.width=8, fig.height=48, warning=FALSE}
## For presenting variability we try now boxplots on individual data (non-aggregated):
dfi %>%
  # sample_n(2000) %>%
  ## Selecting variables:
  select(opinions, boundary, id_threshold, ESBG) %>% 
  mutate(boundary = factor(boundary),
         opinions = factor(opinions)) %>% 
  
  ## Renaming variables according 2022-03-18 meeting:
  prejmenuj(1:3, c("Opinion dimensions:", "Acceptability of different opinion:",  
                    "Narrowness of identity group:")) %>% 

  ## Graph itself:
  ggplot() +
  aes(fill = `Acceptability of different opinion:`, y = ESBG, 
      x = `Narrowness of identity group:`,
      group = `Narrowness of identity group:`, 
      col = `Acceptability of different opinion:`) +
  facet_wrap(vars(`Acceptability of different opinion:`, `Opinion dimensions:`), ncol=3) +
  geom_boxplot(alpha = 0.2) +
  geom_jitter(alpha = 0.2) +
  scale_x_continuous(breaks = seq(0.05, 0.85, 0.1)) +
  labs(title = "Change of polarization in simulations by 'Opinion dimensions' (1, 2, 4),\n'Narrowness of identity group' (0.05--0.85) and 'Average acceptability of different opinions' (0.05--0.5)",
       y = "Polarization") +
  guides(fill = "none", color = "none") +
  theme_minimal() +
  theme(legend.position = "top")  

```


### Narrownes: reduced scatter plot

Now, same data but slightly different graph

```{r graph7, fig.width=8, fig.height=12, warning=FALSE}
## For presenting variability we try now boxplots on individual data (non-aggregated):
dfi %>%
  filter(round(100 * boundary, 0) %in% seq(5, 50, 5)) %>% 
  # sample_n(2000) %>%
  ## Selecting variables:
  select(opinions, boundary, id_threshold, ESBG) %>% 

  ## Changing some variables to factors:
  mutate(boundary = factor(boundary),
         opinions = factor(opinions)) %>% 

  ## Renaming variables according 2022-03-18 meeting:
  prejmenuj(1:3, c("Opinion dimensions:", "Acceptability of different opinion:",  
                    "Narrowness of identity group:")) %>% 

  ## Graph itself:
  ggplot(aes(fill = `Acceptability of different opinion:`, y = ESBG, 
             x = `Narrowness of identity group:`,
             col = `Acceptability of different opinion:`)) +
  facet_wrap(vars(`Acceptability of different opinion:`, `Opinion dimensions:`), ncol=3) +
  geom_point(alpha = 0.15) +
  scale_x_continuous(breaks = seq(0.05, 0.85, 0.1)) +
  labs(title = "Change of polarization in simulations by 'Opinion dimensions' (1, 2, 4),\n'Narrowness of identity group' (0.05--0.85) and 'Average acceptability of different opinions' (0.05--0.5)",
       y = "Polarization") +
  guides(fill = "none", color = "none") +
  theme_minimal() +
  theme(legend.position = "top")

```


### Narrownes: full scatter plot  

Now, same graph again with complete data:

```{r graph8, fig.width=8, fig.height=48, warning=FALSE}
## For presenting variability we try now boxplots on individual data (non-aggregated):
dfi %>%
  # sample_n(2000) %>%
  ## Selecting variables:
  select(opinions, boundary, id_threshold, ESBG) %>% 

  ## Changing some variables to factors:
  mutate(boundary = factor(boundary),
         opinions = factor(opinions)) %>% 

  ## Renaming variables according 2022-03-18 meeting:
  prejmenuj(1:3, c("Opinion dimensions:", "Acceptability of different opinion:",  
                    "Narrowness of identity group:")) %>% 

  ## Graph itself:
  ggplot(aes(fill = `Acceptability of different opinion:`, y = ESBG, 
             x = `Narrowness of identity group:`,
             col = `Acceptability of different opinion:`)) +
  facet_wrap(vars(`Acceptability of different opinion:`, `Opinion dimensions:`), ncol=3) +
  geom_point(alpha = 0.15) +
  scale_x_continuous(breaks = seq(0.05, 0.85, 0.1)) +
  labs(title = "Change of polarization in simulations by 'Opinion dimensions' (1, 2, 4),\n'Narrowness of identity group' (0.05--0.85) and 'Average acceptability of different opinions' (0.05--0.5)",
        y = "Polarization") +
  guides(fill = "none", color = "none") +
  theme_minimal() +
  theme(legend.position = "top")

```



# Regression   

```{r regression}

m = lm(ESBG ~ factor(opinions)+id_threshold+boundary, data = filter(dfi, identity))
ms = summary(m)

p1 = lm(ESBG ~ factor(opinions)+factor(id_threshold)+factor(boundary), data = filter(dfi, identity))
p1s = summary(p1)
p1s

# f = lm(ESBG ~ factor(opinions)*factor(id_threshold)*factor(boundary), data = filter(dfi, identity))
# fs = summary(f)


```



I just wanna know how much variability we can explain by the full model. But I am not able to estimate the full model, since with fully factorized variables there are `11 177` (!sic) variables and interactions. Dataset is rich enough for this, but memory of my PC is not :-) Later we might try estimate the explanation by full model on Unity. But preliminary estimate shows that we pay more than 10,000 degrees of freedom by including all the interactions, but we get something around of 2 more percent points of variability explained -- it totally doesn't worth for such a high price! 


OK, by `fully factorized main effects only` model  we might explain `r (100 * p1s[['r.squared']]) %>% round(1)` %, it means there is `r (100 - 100 * p1s[['r.squared']]) %>% round(1)` % of variability, which is unexplainable in principle! Resp. we can't explain it by any variable which we manipulated during simulation experiments. As I mentioned above, we might try explain it via detailed description of initial condition (however randomly generated) or via description of the course of the simulation.  

BTW, `fully factorized model with main effects only` is the best (difference in BIC `r round((BIC(p1) - BIC(m))/1000, 0)`k), this model is better regarding the BIC than the `non-factorized main effects` model. Just for order, the model with `non-factorized main effects` explains `r (100 * summary(m)[['r.squared']]) %>% round(1)` % of variability.



