{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "735801a6-5cad-4958-8ff6-8d7cb1b8a495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# PARAMS\n",
    "use_media = True # Flag for whether the analysis needs to account for media agents\n",
    "thickness_by_SPIRO = False #whether the trajectory thicknesses scale with SPIRO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922120db-f4d5-4b2d-947f-05ea0f6bbe61",
   "metadata": {},
   "source": [
    " ## Define the file or folder path here\n",
    " \n",
    " One can either specify a specific file (set the read_specific_file flag to true and set folder path and file title accordingly), or one can read all files in the folder path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ac6615-52b6-4f52-9108-7529b46bb7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found these files: \n",
      "\n",
      "fine-grained-data ___boundaryMean0.219___boundarySD0.2___OpinionMean0___OpinionSD0.2___OpinionDistributionnormal___NetworkTypeScale-free___RS1___MediaOpinions[-0.9 -0.7 0 0.7 0.9]\n",
      "\n",
      "fine-grained-data ___boundaryMean0.246___boundarySD0.2___OpinionMean0___OpinionSD0.2___OpinionDistributionnormal___NetworkTypeScale-free___RS1___MediaOpinions[-0.3 -0.2 0 0.2 0.3]\n",
      "\n",
      "fine-grained-data ___boundaryMean0.246___boundarySD0.2___OpinionMean0___OpinionSD0.2___OpinionDistributionnormal___NetworkTypeScale-free___RS1___MediaOpinions[-0.9 -0.5 -0.3 -0.2 0 0.2 0.3 0.5 0.9]\n",
      "\n",
      "fine-grained-data ___boundaryMean0.246___boundarySD0.2___OpinionMean0___OpinionSD0.2___OpinionDistributionnormal___NetworkTypeScale-free___RS1___MediaOpinions[0]\n",
      "\n",
      "fine-grained-data ___boundaryMean0.246___boundarySD0.2___OpinionMean0___OpinionSD0.2___OpinionDistributionnormal___NetworkTypeScale-free___RS1___MediaOpinions[]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_specific_file = False\n",
    "\n",
    "\n",
    "list_file_paths = []\n",
    "list_file_titles = []\n",
    "\n",
    "\n",
    "folder_path = \"data\\\\trial\" # set the folder path here wrt the ipynb root.\n",
    "\n",
    "if read_specific_file:\n",
    "    file_title = \"fine-grained-data ___boundaryMean0.35___boundarySD0.2___OpinionMean0___OpinionSD0.2___OpinionDistributionnormal___NetworkTypeScale-free___RS1___MediaOpinions[-0.9 -0.7 0 0.7 0.9]\"\n",
    "    file_name = file_title + \".csv\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    list_file_paths.append(file_path)\n",
    "    list_file_titles = [file_title]  # Store without extension    \n",
    "else:\n",
    "    # Read all CSV files in the folder\n",
    "    list_dir = os.listdir(folder_path)\n",
    "    for f in list_dir:\n",
    "        if f.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, f)\n",
    "            list_file_paths.append(file_path)\n",
    "            # Remove the .csv extension and store\n",
    "            list_file_titles.append(os.path.splitext(f)[0])\n",
    "\n",
    "        \n",
    "\n",
    "# Now you can use list_file_titles for reference\n",
    "print(\"Found these files: \\n\")\n",
    "for title in list_file_titles:\n",
    "    print(title + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8d2fb36-d661-46ef-a376-b916073c2e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(\"Current working directory:\", os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70856ed6-e2b4-4f1c-970a-092b2805298b",
   "metadata": {},
   "source": [
    " ## Reading metadata then the data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0647dedc-d0df-4d6b-8f53-490ee5f9721e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\explr\\fine-grained-data ___boundaryMean0.219___boundarySD0.2___OpinionMean0___OpinionSD0.2___OpinionDistributionnormal___NetworkTypeScale-free___RS1___MediaOpinions[-0.9 -0.7 0 0.7 0.9].csv\n",
      "data\\explr\\fine-grained-data ___boundaryMean0.246___boundarySD0.2___OpinionMean0___OpinionSD0.2___OpinionDistributionnormal___NetworkTypeScale-free___RS1___MediaOpinions[-0.3 -0.2 0 0.2 0.3].csv\n",
      "data\\explr\\fine-grained-data ___boundaryMean0.246___boundarySD0.2___OpinionMean0___OpinionSD0.2___OpinionDistributionnormal___NetworkTypeScale-free___RS1___MediaOpinions[-0.9 -0.5 -0.3 -0.2 0 0.2 0.3 0.5 0.9].csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\explr\\\\fine-grained-data ___boundaryMean0.246___boundarySD0.2___OpinionMean0___OpinionSD0.2___OpinionDistributionnormal___NetworkTypeScale-free___RS1___MediaOpinions[-0.9 -0.5 -0.3 -0.2 0 0.2 0.3 0.5 0.9].csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(file_path)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Read the entire file\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     11\u001b[0m     lines \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m     13\u001b[0m separator \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\explr\\\\fine-grained-data ___boundaryMean0.246___boundarySD0.2___OpinionMean0___OpinionSD0.2___OpinionDistributionnormal___NetworkTypeScale-free___RS1___MediaOpinions[-0.9 -0.5 -0.3 -0.2 0 0.2 0.3 0.5 0.9].csv'"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "list_dataframes = [] # list of dataframes for all files in folder\n",
    "list_metadata_dict = []\n",
    "list_media_positions = []\n",
    "\n",
    "for file_path in list_file_paths:\n",
    "    print(file_path)\n",
    "    # Read the entire file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    separator = \"-----------------\"\n",
    "    sep_indices = [i for i, line in enumerate(lines) if separator in line]\n",
    "\n",
    "    # Step 1: Extract metadata (before first separator)\n",
    "    metadata_lines = lines[:sep_indices[0]]\n",
    "    metadata_df = pd.read_csv(StringIO(''.join(metadata_lines)), header=None)\n",
    "    metadata_dict = dict(zip(metadata_df[0], metadata_df[1]))\n",
    "    list_metadata_dict.append(metadata_dict)\n",
    "\n",
    "    # Step 2: Identify where the main CSV data starts (after last separator)\n",
    "    data_start_index = sep_indices[-1] + 1\n",
    "    data_lines = lines[data_start_index:]\n",
    "\n",
    "    # Step 3: Convert data_lines into a file-like object for pandas\n",
    "    from io import StringIO\n",
    "    data_csv = StringIO(\"\".join(data_lines))\n",
    "\n",
    "    # Step 4: Read it into a dataframe\n",
    "    this_df = pd.read_csv(data_csv)\n",
    "    list_dataframes.append(this_df)\n",
    "        \n",
    "    # Check each file\n",
    "    # print(\"✅ Metadata dictionary:\\n\", metadata_dict)\n",
    "    # print(\"\\n✅ Main dataframe columns:\\n\", df.columns)\n",
    "    # print(\"\\n✅ First few rows of data:\\n\", df.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c40effb-682e-491e-b548-19280b43a7c6",
   "metadata": {},
   "source": [
    " ## Some needed cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496b956-b8b1-49d4-baeb-04cc66c37341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idf, df in enumerate(list_dataframes):\n",
    "    # To remove accidental spaces before the column name\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if(use_media == True):\n",
    "        # Clean 'Media-House-Positions' in metadata_dict\n",
    "        media_str = list_metadata_dict[idf].get('Media-House-Positions', '')  # get the string from metadata\n",
    "        media_str = media_str.strip('[]')  # remove brackets\n",
    "        media_positions = [float(x) for x in media_str.split()]  # convert to list of floats\n",
    "        list_media_positions.append(media_positions)\n",
    "    # 'opinion' and 'previousOpinion' have leading and ending brackets and need to be converted to numerics\n",
    "    df['opinion'] = pd.to_numeric(df['opinion'].str.strip(\"[]\"))\n",
    "    df['previousOpinion'] = pd.to_numeric(df['previousOpinion'].str.strip(\"[]\"))\n",
    "\n",
    "    # Remove brackets and convert space-separated string into list of ints\n",
    "    df[\"influencerIDs\"] = df[\"Influencer ID's\"].str.strip(\"[]\").apply(lambda x: [int(i) for i in x.split()])\n",
    "\n",
    "    # print(df)\n",
    "    print(list_media_positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b3687d-346b-43f3-ad9c-d3d4cfe2fa29",
   "metadata": {},
   "source": [
    "## Opinion Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c04f172-7fca-45c2-8a53-ab41560f8402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for idf, df in enumerate(list_dataframes):\n",
    "# Extract metadata values\n",
    "    mu_epsilon = list_metadata_dict[idf][\"boundary-mean\"]  # Mean boundary\n",
    "    sigma_epsilon = list_metadata_dict[idf][\"boundary-sd\"]  # Std boundary\n",
    "    mu_SPIRO = list_metadata_dict[idf][\"SPIRO-mean\"]  # Mean SPIRO\n",
    "    sigma_SPIRO = list_metadata_dict[idf][\"SPIRO-sd\"]  # Std SPIRO\n",
    "\n",
    "\n",
    "    # Normalize boundary values to a colormap range (0 to 1)\n",
    "    norm = plt.Normalize(df[\"boundary\"].min(), df[\"boundary\"].max())\n",
    "    cmap = plt.cm.viridis  # Choose colormap\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)  # Create color mapping\n",
    "\n",
    "    # Sort agents by boundary in ascending order\n",
    "    sorted_agents = df.groupby(\"agentID\").first().sort_values(by=\"boundary\").index\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 9))\n",
    "\n",
    "    # Loop through each agent in sorted order (low boundary first, high boundary last)\n",
    "    for agent_id in sorted_agents:\n",
    "        agent_data = df[df[\"agentID\"] == agent_id]\n",
    "\n",
    "        if(thickness_by_SPIRO):\n",
    "            linewidth = 1.5 + 2*(0.25 - agent_data[\"SPIRO\"].iloc[0])\n",
    "        else:\n",
    "            linewidth = 1 # Haardcoding it away from potentially problematic SPIRO values.\n",
    "\n",
    "        color = cmap(norm(agent_data[\"boundary\"].iloc[0]))  # Pick color based on first boundary value\n",
    "        ax.plot(agent_data[\"timeStep\"], agent_data[\"opinion\"], color=color, alpha=0.8, linewidth=linewidth)\n",
    "\n",
    "    if(use_media):\n",
    "        # Plot horizontal lines for media opinions\n",
    "        for i, media_opinion in enumerate(list_media_positions[idf]):\n",
    "            ax.axhline(y=media_opinion, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "            ax.text(\n",
    "                x=370,  # Just outside the x-limit for a neat label\n",
    "                y=media_opinion,\n",
    "                s=f\"Media {i+1}\",\n",
    "                color='red',\n",
    "                va='center',\n",
    "                fontsize=12,\n",
    "                fontweight='bold'\n",
    "            )\n",
    "\n",
    "    # Add colorbar\n",
    "    cbar = fig.colorbar(sm, ax=ax)\n",
    "    cbar.set_label(\"Agent Open-Mindedness ($\\\\epsilon_{i}$)\", fontsize = 18)\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.xlim([0, 365])\n",
    "    ax.set_xlabel(\"Time Step\", fontsize = 18)\n",
    "    ax.set_ylabel(f\"Opinion\", fontsize = 18)\n",
    "    # LaTeX formatted title with subscripts\n",
    "    ax.set_title(\n",
    "        f\"Opinion Evolution Over Time under Media influence\\n\"\n",
    "        f\"$\\\\mu_\\\\epsilon$ = {mu_epsilon}, $\\\\sigma_\\\\epsilon$ = {sigma_epsilon}, \"\n",
    "        f\"$\\\\mu_{{SPIRO}}$ = {mu_SPIRO}, $\\\\sigma_{{SPIRO}}$ = {sigma_SPIRO}\", fontsize = 18\n",
    "    )\n",
    "    ax.grid(True, linestyle=\"-\", alpha=0.5)\n",
    "\n",
    "\n",
    "    this_figure_path = os.path.join(folder_path, list_file_titles[idf] + \".png\")\n",
    "    plt.savefig(this_figure_path, dpi=200, bbox_inches='tight')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbac008-1e0f-46e9-a924-1f1e90537dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import glob\n",
    "\n",
    "# # Create and save individual frames\n",
    "# for t in np.arange(365):\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     t_data = df[df[\"timeStep\"] == t]\n",
    "#     plt.hist(t_data[\"opinion\"], bins=200, range=(-1, 6))\n",
    "#     plt.xlim(-1, 1)\n",
    "#     plt.ylim(0, 550)\n",
    "#     plt.title(f'Time Step: {t}')\n",
    "#     plt.savefig(f'temp/frame_{t:03d}.png')\n",
    "#     plt.close()\n",
    "\n",
    "# # Combine into GIF (requires ImageMagick)\n",
    "# frames = [Image.open(img) for img in sorted(glob.glob(\"temp/frame_*.png\"))]\n",
    "# frames[0].save('opinion_evolution.gif',\n",
    "#                format='GIF',\n",
    "#                append_images=frames[1:],\n",
    "#                save_all=True,\n",
    "#                duration=150,  # ms per frame\n",
    "#                loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982db1d0-4035-41e8-8035-cb6ac1975e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Normality\n",
    "\n",
    "\n",
    "from scipy.stats import lognorm\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import shapiro \n",
    "\n",
    "for df in list_dataframes:\n",
    "    shapiro_data = np.array([])\n",
    "\n",
    "    for t in np.arange(0, 20):\n",
    "\n",
    "        # plt.figure(figsize=(10, 6))\n",
    "        t_data = df[df[\"timeStep\"] == t]\n",
    "\n",
    "        #create Q-Q plot with 45-degree line added to plot\n",
    "        # fig = sm.qqplot(t_data[\"opinion\"], line='45')\n",
    "        shapiro_data = np.append(shapiro_data, shapiro(t_data[\"opinion\"]).pvalue)\n",
    "    \n",
    "    #Plotting the shapiro p value across time\n",
    "    fig, ax = plt.subplots(figsize=(15, 9))\n",
    "    plt.plot(shapiro_data)\n",
    "    plt.ylim([0, 0.07])\n",
    "\n",
    "    # LaTeX formatted title with subscripts\n",
    "    ax.set_title(\n",
    "        f\"Shapiro p-value in first 20 Time Steps\\n\"\n",
    "        f\"$\\\\mu_\\\\epsilon$ = {mu_epsilon}, $\\\\sigma_\\\\epsilon$ = {sigma_epsilon}, \"\n",
    "        f\"$\\\\mu_{{SPIRO}}$ = {mu_SPIRO}, $\\\\sigma_{{SPIRO}}$ = {sigma_SPIRO}\", fontsize = 18\n",
    "    )    # print(shapiro_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d01b3c-07af-4ea0-85b5-ea63b7e58020",
   "metadata": {},
   "source": [
    "## Seeing Group Structure evolve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e828b-7546-49f3-add1-4db0c99e6450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# # ----- First Plot: Number of Unique Groups Over Time -----\n",
    "# unique_groups_per_time = df.groupby(\"timeStep\")[\"groupNumber\"].nunique()\n",
    "\n",
    "# # ----- Second Plot: Fraction of Agents in Groups Over Time -----\n",
    "# # Step 1: Count agents in each group at each time step\n",
    "# agents_per_group = df.groupby([\"timeStep\", \"groupNumber\"])[\"agentID\"].count()\n",
    "\n",
    "# # Step 2: Compute total agents per time step\n",
    "# total_agents_per_time = agents_per_group.groupby(\"timeStep\").sum()\n",
    "\n",
    "# # Step 3: Convert counts to fractions by dividing each group count by the total agents at that time step\n",
    "# agents_fraction_per_group = agents_per_group.div(total_agents_per_time, level=\"timeStep\")\n",
    "\n",
    "# # Step 4: Pivot table to get a wide format (timeStep as rows, group sizes as columns)\n",
    "# fraction_per_time_wide = agents_fraction_per_group.unstack(fill_value=0)\n",
    "\n",
    "# # Step 5: Sort each row’s values in descending order (largest groups first)\n",
    "# sorted_fractions = fraction_per_time_wide.apply(lambda x: sorted(x, reverse=True), axis=1, result_type=\"expand\")\n",
    "\n",
    "# # ----- Create the Figure with Two Subplots -----\n",
    "# fig, ax = plt.subplots(figsize=(15, 9))\n",
    "\n",
    "\n",
    "# # # Second subplot: Stacked Bar Chart of Group Fractions Over Time\n",
    "# sorted_fractions.plot(kind=\"bar\", stacked=True, ax=axes[1], width=1, cmap=\"viridis\", alpha=0.8)\n",
    "\n",
    "# # # Formatting for second plot\n",
    "# # axes[1].set_xlabel(\"Time Step\", fontsize=14)\n",
    "# # axes[1].set_ylabel(\"Fraction of Agents\", fontsize=14)\n",
    "# # axes[1].grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "# # axes[1].legend_.remove()  # Hide legend since group numbers aren't meaningful\n",
    "\n",
    "# # Adjust layout\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a82b6dd-baa1-4944-8831-5ba8f0857b4c",
   "metadata": {},
   "source": [
    "## Media Houses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
