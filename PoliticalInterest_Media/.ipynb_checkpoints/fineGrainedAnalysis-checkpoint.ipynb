{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "735801a6-5cad-4958-8ff6-8d7cb1b8a495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# PARAMS\n",
    "use_media = True # Flag for whether the analysis needs to account for media agents\n",
    "dynamic_media = True # Flag for whether media position changes over time.\n",
    "thickness_by_SPIRO = False #whether the trajectory thicknesses scale with SPIRO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922120db-f4d5-4b2d-947f-05ea0f6bbe61",
   "metadata": {},
   "source": [
    " ## Define the file or folder path here\n",
    " \n",
    " One can either specify a specific file (set the read_specific_file flag to true and set folder path and file title accordingly), or one can read all files in the folder path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ac6615-52b6-4f52-9108-7529b46bb7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found these files: \n",
      "\n",
      "epsM0.333_epsSD0.084___OpDuniform_OpM0_OpSD0.2___NetScale-free___RS998587752___Med[-0.7 0 0.7]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_specific_file = False\n",
    "\n",
    "\n",
    "list_file_paths = []\n",
    "list_file_titles = []\n",
    "\n",
    "\n",
    "folder_path = \"data\\\\GrowingMediaNumbers\" # set the folder path here wrt the ipynb root.\n",
    "\n",
    "if read_specific_file:\n",
    "    file_title = \"fine-grained-data ___boundaryMean0.35___boundarySD0.2___OpinionMean0___OpinionSD0.2___OpinionDistributionnormal___NetworkTypeScale-free___RS1___MediaOpinions[-0.9 -0.7 0 0.7 0.9]\"\n",
    "    file_name = file_title + \".csv\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    list_file_paths.append(file_path)\n",
    "    list_file_titles = [file_title]  # Store without extension    \n",
    "else:\n",
    "    # Read all CSV files in the folder\n",
    "    list_dir = os.listdir(folder_path)\n",
    "    for f in list_dir:\n",
    "        if f.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, f)\n",
    "            list_file_paths.append(file_path)\n",
    "            # Remove the .csv extension and store\n",
    "            list_file_titles.append(os.path.splitext(f)[0])\n",
    "\n",
    "        \n",
    "\n",
    "# Now you can use list_file_titles for reference\n",
    "print(\"Found these files: \\n\")\n",
    "for title in list_file_titles:\n",
    "    print(title + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8d2fb36-d661-46ef-a376-b916073c2e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(\"Current working directory:\", os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70856ed6-e2b4-4f1c-970a-092b2805298b",
   "metadata": {},
   "source": [
    " ## Reading metadata then the data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0647dedc-d0df-4d6b-8f53-490ee5f9721e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\GrowingMediaNumbers\\epsM0.333_epsSD0.084___OpDuniform_OpM0_OpSD0.2___NetScale-free___RS998587752___Med[-0.7 0 0.7].csv\n",
      "✅ Metadata dictionary:\n",
      " {'random-seed': '998587752', 'conformity-mean': '0.508', 'conformity-sd': '0', 'conformity-distribution': 'normal', 'HK-distribution': 'false', 'N': '1000', 'boundary-mean': '0.333', 'boundary-sd': '0.084', 'boundary-distribution': 'normal', 'SPIRO-mean': '1', 'SPIRO-sd': '0', 'SPIRO-distribution': 'covert', 'Identity-Type': 'global', 'Identity-Levels': '7', 'Use_Identity?': 'false', 'Media-House-Positions': '[-0.7 0 0.7]', 'Ticks_Between_N_Media_Change': '26', 'Delta_N_Media': '1'}\n",
      "\n",
      "✅ Main dataframe columns:\n",
      " Index(['timeStep', ' agentType', ' agentID', ' opinion', ' previousOpinion',\n",
      "       ' boundary', ' conformity', ' SPIRO', ' groupNumber',\n",
      "       ' Influencer ID's'],\n",
      "      dtype='object')\n",
      "\n",
      "✅ First few rows of data:\n",
      "    timeStep   agentType   agentID               opinion  previousOpinion  \\\n",
      "0         0  Individual       101            [0.325668]          [0.442]   \n",
      "1         0  Individual       863            [0.870528]          [0.964]   \n",
      "2         0  Individual       985           [-0.422116]         [-0.383]   \n",
      "3         0  Individual       841  [0.8392999999999999]          [0.979]   \n",
      "4         0  Individual       856            [0.800976]          [0.866]   \n",
      "\n",
      "    boundary   conformity   SPIRO   groupNumber  \\\n",
      "0      0.322        0.508     1.0        1101.0   \n",
      "1      0.348        0.508     1.0        1101.0   \n",
      "2      0.338        0.508     1.0        1102.0   \n",
      "3      0.378        0.508     1.0        1101.0   \n",
      "4      0.275        0.508     1.0        1101.0   \n",
      "\n",
      "                   Influencer ID's  \n",
      "0  [101 619 738 824 927 1001 1002]  \n",
      "1             [9 490 863 884 1002]  \n",
      "2        [58 63 369 985 1000 1001]  \n",
      "3           [293 793 841 987 1002]  \n",
      "4                   [785 856 1002]  \n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "list_dataframes = [] # list of dataframes for all files in folder\n",
    "list_metadata_dict = []\n",
    "list_media_positions = []\n",
    "\n",
    "for file_path in list_file_paths:\n",
    "    print(file_path)\n",
    "    # Read the entire file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    separator = \"-----------------\"\n",
    "    sep_indices = [i for i, line in enumerate(lines) if separator in line]\n",
    "\n",
    "    # Step 1: Extract metadata (before first separator)\n",
    "    metadata_lines = lines[:sep_indices[0]]\n",
    "    metadata_df = pd.read_csv(StringIO(''.join(metadata_lines)), header=None)\n",
    "    metadata_dict = dict(zip(metadata_df[0], metadata_df[1]))\n",
    "    list_metadata_dict.append(metadata_dict)\n",
    "\n",
    "    # Step 2: Identify where the main CSV data starts (after last separator)\n",
    "    data_start_index = sep_indices[-1] + 1\n",
    "    data_lines = lines[data_start_index:]\n",
    "\n",
    "    # Step 3: Convert data_lines into a file-like object for pandas\n",
    "    from io import StringIO\n",
    "    data_csv = StringIO(\"\".join(data_lines))\n",
    "\n",
    "    # Step 4: Read it into a dataframe\n",
    "    this_df = pd.read_csv(data_csv)\n",
    "    list_dataframes.append(this_df)\n",
    "        \n",
    "    # Check each file\n",
    "    print(\"✅ Metadata dictionary:\\n\", metadata_dict)\n",
    "    print(\"\\n✅ Main dataframe columns:\\n\", this_df.columns)\n",
    "    print(\"\\n✅ First few rows of data:\\n\", this_df.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97052f48-b7c4-45b8-ae37-4b326877ec77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random-seed': '998587752',\n",
       " 'conformity-mean': '0.508',\n",
       " 'conformity-sd': '0',\n",
       " 'conformity-distribution': 'normal',\n",
       " 'HK-distribution': 'false',\n",
       " 'N': '1000',\n",
       " 'boundary-mean': '0.333',\n",
       " 'boundary-sd': '0.084',\n",
       " 'boundary-distribution': 'normal',\n",
       " 'SPIRO-mean': '1',\n",
       " 'SPIRO-sd': '0',\n",
       " 'SPIRO-distribution': 'covert',\n",
       " 'Identity-Type': 'global',\n",
       " 'Identity-Levels': '7',\n",
       " 'Use_Identity?': 'false',\n",
       " 'Media-House-Positions': '[-0.7 0 0.7]',\n",
       " 'Ticks_Between_N_Media_Change': '26',\n",
       " 'Delta_N_Media': '1'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c40effb-682e-491e-b548-19280b43a7c6",
   "metadata": {},
   "source": [
    " ## Some needed cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9496b956-b8b1-49d4-baeb-04cc66c37341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         False\n",
      "1         False\n",
      "2         False\n",
      "3         False\n",
      "4         False\n",
      "          ...  \n",
      "366090    False\n",
      "366091    False\n",
      "366092     True\n",
      "366093     True\n",
      "366094     True\n",
      "Name: agentType, Length: 366095, dtype: bool\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magentType\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedia\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Remove brackets and convert space-separated string into list of ints\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfluencerIDs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInfluencer ID\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [\u001b[38;5;28mint\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39msplit()])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4640\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4758\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4759\u001b[0m         func,\n\u001b[0;32m   4760\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4761\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4762\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4763\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4764\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1290\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1291\u001b[0m )\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[26], line 20\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magentType\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedia\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Remove brackets and convert space-separated string into list of ints\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfluencerIDs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInfluencer ID\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [\u001b[38;5;28mint\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39msplit()])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "for idf, df in enumerate(list_dataframes):\n",
    "    # Split into Individuals and Media DataFrames\n",
    "    df = df[df['agentType'] == 'Individual'].copy()\n",
    "    media_df = df[df['agentType'] == 'Media'].copy()\n",
    "\n",
    "    \n",
    "    # To remove accidental spaces before the column name\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if(use_media == True):\n",
    "        # Clean 'Media-House-Positions' in metadata_dict\n",
    "        media_str = list_metadata_dict[idf].get('Media-House-Positions', '')  # get the string from metadata\n",
    "        media_str = media_str.strip('[]')  # remove brackets\n",
    "        media_positions = [float(x) for x in media_str.split()]  # convert to list of floats\n",
    "        list_media_positions.append(media_positions)\n",
    "        \n",
    "        \n",
    "    # 'opinion' and 'previousOpinion' have leading and ending brackets and need to be converted to numerics\n",
    "    df['opinion'] = pd.to_numeric(df['opinion'].str.strip(\"[]\"))\n",
    "    df['previousOpinion'] = pd.to_numeric(df['previousOpinion'].str.strip(\"[]\"))\n",
    "    print(df[\"agentType\"]==\"Media\")\n",
    "    # Remove brackets and convert space-separated string into list of ints\n",
    "    df[\"influencerIDs\"] = df[\"Influencer ID's\"].str.strip(\"[]\").apply(lambda x: [int(i) for i in x.split()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b3687d-346b-43f3-ad9c-d3d4cfe2fa29",
   "metadata": {},
   "source": [
    "## Opinion Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c04f172-7fca-45c2-8a53-ab41560f8402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for idf, df in enumerate(list_dataframes):\n",
    "# Extract metadata values\n",
    "    mu_epsilon = list_metadata_dict[idf][\"boundary-mean\"]  # Mean boundary\n",
    "    sigma_epsilon = list_metadata_dict[idf][\"boundary-sd\"]  # Std boundary\n",
    "    mu_SPIRO = list_metadata_dict[idf][\"SPIRO-mean\"]  # Mean SPIRO\n",
    "    sigma_SPIRO = list_metadata_dict[idf][\"SPIRO-sd\"]  # Std SPIRO\n",
    "\n",
    "\n",
    "    # Normalize boundary values to a colormap range (0 to 1)\n",
    "    norm = plt.Normalize(df[\"boundary\"].min(), df[\"boundary\"].max())\n",
    "    cmap = plt.cm.viridis  # Choose colormap\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)  # Create color mapping\n",
    "\n",
    "    # Sort agents by boundary in ascending order\n",
    "    sorted_agents = df.groupby(\"agentID\").first().sort_values(by=\"boundary\").index\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 9))\n",
    "\n",
    "    # Loop through each agent in sorted order (low boundary first, high boundary last)\n",
    "    for agent_id in sorted_agents:\n",
    "        agent_data = df[df[\"agentID\"] == agent_id]\n",
    "\n",
    "        if(thickness_by_SPIRO):\n",
    "            linewidth = 1.5 + 2*(0.25 - agent_data[\"SPIRO\"].iloc[0])\n",
    "        else:\n",
    "            linewidth = 1 # Haardcoding it away from potentially problematic SPIRO values.\n",
    "\n",
    "        color = cmap(norm(agent_data[\"boundary\"].iloc[0]))  # Pick color based on first boundary value\n",
    "        ax.plot(agent_data[\"timeStep\"], agent_data[\"opinion\"], color=color, alpha=0.8, linewidth=linewidth)\n",
    "\n",
    "    if(use_media):\n",
    "        # Plot horizontal lines for media opinions\n",
    "        for i, media_opinion in enumerate(list_media_positions[idf]):\n",
    "            ax.axhline(y=media_opinion, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "            ax.text(\n",
    "                x=370,  # Just outside the x-limit for a neat label\n",
    "                y=media_opinion,\n",
    "                s=f\"Media {i+1}\",\n",
    "                color='red',\n",
    "                va='center',\n",
    "                fontsize=12,\n",
    "                fontweight='bold'\n",
    "            )\n",
    "\n",
    "    # Add colorbar\n",
    "    cbar = fig.colorbar(sm, ax=ax)\n",
    "    cbar.set_label(\"Agent Open-Mindedness ($\\\\epsilon_{i}$)\", fontsize = 18)\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.xlim([0, 365])\n",
    "    ax.set_xlabel(\"Time Step\", fontsize = 18)\n",
    "    ax.set_ylabel(f\"Opinion\", fontsize = 18)\n",
    "    # LaTeX formatted title with subscripts\n",
    "    ax.set_title(\n",
    "        f\"Opinion Evolution Over Time under Media influence\\n\"\n",
    "        f\"$\\\\mu_\\\\epsilon$ = {mu_epsilon}, $\\\\sigma_\\\\epsilon$ = {sigma_epsilon}, \"\n",
    "        f\"$\\\\mu_{{SPIRO}}$ = {mu_SPIRO}, $\\\\sigma_{{SPIRO}}$ = {sigma_SPIRO}\", fontsize = 18\n",
    "    )\n",
    "    ax.grid(True, linestyle=\"-\", alpha=0.5)\n",
    "\n",
    "\n",
    "    this_figure_path = os.path.join(folder_path, list_file_titles[idf] + \".png\")\n",
    "    plt.savefig(this_figure_path, dpi=200, bbox_inches='tight')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbac008-1e0f-46e9-a924-1f1e90537dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import glob\n",
    "\n",
    "# # Create and save individual frames\n",
    "# for t in np.arange(365):\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     t_data = df[df[\"timeStep\"] == t]\n",
    "#     plt.hist(t_data[\"opinion\"], bins=200, range=(-1, 6))\n",
    "#     plt.xlim(-1, 1)\n",
    "#     plt.ylim(0, 550)\n",
    "#     plt.title(f'Time Step: {t}')\n",
    "#     plt.savefig(f'temp/frame_{t:03d}.png')\n",
    "#     plt.close()\n",
    "\n",
    "# # Combine into GIF (requires ImageMagick)\n",
    "# frames = [Image.open(img) for img in sorted(glob.glob(\"temp/frame_*.png\"))]\n",
    "# frames[0].save('opinion_evolution.gif',\n",
    "#                format='GIF',\n",
    "#                append_images=frames[1:],\n",
    "#                save_all=True,\n",
    "#                duration=150,  # ms per frame\n",
    "#                loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982db1d0-4035-41e8-8035-cb6ac1975e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Normality\n",
    "\n",
    "\n",
    "from scipy.stats import lognorm\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import shapiro \n",
    "\n",
    "for df in list_dataframes:\n",
    "    shapiro_data = np.array([])\n",
    "\n",
    "    for t in np.arange(0, 20):\n",
    "\n",
    "        # plt.figure(figsize=(10, 6))\n",
    "        t_data = df[df[\"timeStep\"] == t]\n",
    "\n",
    "        #create Q-Q plot with 45-degree line added to plot\n",
    "        # fig = sm.qqplot(t_data[\"opinion\"], line='45')\n",
    "        shapiro_data = np.append(shapiro_data, shapiro(t_data[\"opinion\"]).pvalue)\n",
    "    \n",
    "    #Plotting the shapiro p value across time\n",
    "    fig, ax = plt.subplots(figsize=(15, 9))\n",
    "    plt.plot(shapiro_data)\n",
    "    plt.ylim([0, 0.5])\n",
    "\n",
    "    # LaTeX formatted title with subscripts\n",
    "    ax.set_title(\n",
    "        f\"Shapiro p-value in first 20 Time Steps\\n\"\n",
    "        f\"$\\\\mu_\\\\epsilon$ = {mu_epsilon}, $\\\\sigma_\\\\epsilon$ = {sigma_epsilon}, \"\n",
    "        f\"$\\\\mu_{{SPIRO}}$ = {mu_SPIRO}, $\\\\sigma_{{SPIRO}}$ = {sigma_SPIRO}\", fontsize = 18\n",
    "    )    # print(shapiro_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d01b3c-07af-4ea0-85b5-ea63b7e58020",
   "metadata": {},
   "source": [
    "## Seeing Group Structure evolve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e828b-7546-49f3-add1-4db0c99e6450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# # ----- First Plot: Number of Unique Groups Over Time -----\n",
    "# unique_groups_per_time = df.groupby(\"timeStep\")[\"groupNumber\"].nunique()\n",
    "\n",
    "# # ----- Second Plot: Fraction of Agents in Groups Over Time -----\n",
    "# # Step 1: Count agents in each group at each time step\n",
    "# agents_per_group = df.groupby([\"timeStep\", \"groupNumber\"])[\"agentID\"].count()\n",
    "\n",
    "# # Step 2: Compute total agents per time step\n",
    "# total_agents_per_time = agents_per_group.groupby(\"timeStep\").sum()\n",
    "\n",
    "# # Step 3: Convert counts to fractions by dividing each group count by the total agents at that time step\n",
    "# agents_fraction_per_group = agents_per_group.div(total_agents_per_time, level=\"timeStep\")\n",
    "\n",
    "# # Step 4: Pivot table to get a wide format (timeStep as rows, group sizes as columns)\n",
    "# fraction_per_time_wide = agents_fraction_per_group.unstack(fill_value=0)\n",
    "\n",
    "# # Step 5: Sort each row’s values in descending order (largest groups first)\n",
    "# sorted_fractions = fraction_per_time_wide.apply(lambda x: sorted(x, reverse=True), axis=1, result_type=\"expand\")\n",
    "\n",
    "# # ----- Create the Figure with Two Subplots -----\n",
    "# fig, ax = plt.subplots(figsize=(15, 9))\n",
    "\n",
    "\n",
    "# # # Second subplot: Stacked Bar Chart of Group Fractions Over Time\n",
    "# sorted_fractions.plot(kind=\"bar\", stacked=True, ax=axes[1], width=1, cmap=\"viridis\", alpha=0.8)\n",
    "\n",
    "# # # Formatting for second plot\n",
    "# # axes[1].set_xlabel(\"Time Step\", fontsize=14)\n",
    "# # axes[1].set_ylabel(\"Fraction of Agents\", fontsize=14)\n",
    "# # axes[1].grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "# # axes[1].legend_.remove()  # Hide legend since group numbers aren't meaningful\n",
    "\n",
    "# # Adjust layout\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a82b6dd-baa1-4944-8831-5ba8f0857b4c",
   "metadata": {},
   "source": [
    "## Media Houses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
